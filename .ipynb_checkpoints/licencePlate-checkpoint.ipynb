{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# License Plate Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importing default libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prepare the dataset for YOLO (You Only Look Once) object detection, we can use a Python dictionary. In this code snippet, we define a dictionary called dataset with the following keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {\n",
    "            \"file\":[],\n",
    "            \"width\":[],\n",
    "            \"height\":[],\n",
    "            \"xmin\":[],\n",
    "            \"ymin\":[],\n",
    "            \"xmax\":[],\n",
    "            \"ymax\":[]\n",
    "           }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code snippet, XML annotations are parsed to extract information such as file names, image dimensions, and bounding box coordinates. The information is then added to the dataset dictionary.\n",
    "\n",
    "Make sure to adjust the path_annotations variable to the correct path that contains your XML annotation files. This code snippet assumes that the XML files follow a specific structure where relevant information is stored within specific XML tags.\n",
    "\n",
    "Additionally, the code snippet initializes a list of classes named classes with a single class name 'license'. You can modify this list to include all the classes relevant to your car detection task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_annotations = \"./data/images/annotations/*.xml\"\n",
    "\n",
    "for item in glob.glob(path_annotations):\n",
    "    tree = ET.parse(item)\n",
    "    \n",
    "    for elem in tree.iter():\n",
    "        if 'filename' in elem.tag:\n",
    "            filename=elem.text\n",
    "        elif 'width' in elem.tag:\n",
    "            width=int(elem.text)\n",
    "        elif 'height' in elem.tag:\n",
    "            height=int(elem.text)\n",
    "        elif 'xmin' in elem.tag:\n",
    "            xmin=int(elem.text)\n",
    "        elif 'ymin' in elem.tag:\n",
    "            ymin=int(elem.text)\n",
    "        elif 'xmax' in elem.tag:\n",
    "            xmax=int(elem.text)\n",
    "        elif 'ymax' in elem.tag:\n",
    "            ymax=int(elem.text)\n",
    "            \n",
    "            dataset['file'].append(filename)\n",
    "            dataset['width'].append(width)\n",
    "            dataset['height'].append(height)\n",
    "            dataset['xmin'].append(xmin)\n",
    "            dataset['ymin'].append(ymin)\n",
    "            dataset['xmax'].append(xmax)\n",
    "            dataset['ymax'].append(ymax)\n",
    "        \n",
    "classes = ['license']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DataFrame provides a tabular structure with labeled columns and rows, making it easier to perform various operations, such as data manipulation, filtering, and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(dataset)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rnd\n",
    "from PIL import Image\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random images from a specified directory are displayed along with their corresponding bounding boxes. The bounding box coordinates are retrieved from the df DataFrame.\n",
    "Make sure to adjust the photos_path variable to the correct path that contains your image files. The code snippet assumes that the image files are in PNG format.\n",
    "By calling the print_random_images() function, it will display a specified number of randomly selected images along with their bounding boxes. The bounding box coordinates and class labels are retrieved from the df DataFrame based on the matching image file names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "\n",
    "def print_random_images(photos: list, n: int = 5, seed=None) -> None:\n",
    "    if n > 10:\n",
    "        n=10\n",
    "    \n",
    "    if seed:\n",
    "        rnd.seed(seed)\n",
    "        \n",
    "    random_photos = rnd.sample(photos, n)\n",
    "    \n",
    "    for image_path in random_photos:\n",
    "        \n",
    "        with Image.open(image_path) as fd:\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.imshow(fd)           \n",
    "            ax.axis(False)\n",
    "            \n",
    "            for i, file in enumerate(df.file):\n",
    "                if file in image_path:\n",
    "                    x1,y1,x2,y2=list(df.iloc[i, -4:])\n",
    "                        \n",
    "                    mpatch=mpatches.Rectangle((x1,y1),x2-x1,y2-y1,linewidth=1, edgecolor='b',facecolor=\"none\",lw=2,)                    \n",
    "                    ax.add_patch(mpatch)\n",
    "                    rx, ry = mpatch.get_xy()\n",
    "                    ax.annotate('licence', (rx, ry-2), color='blue', weight='bold', fontsize=12, ha='left', va='baseline')\n",
    "                    \n",
    "photos_path = \"./data/images/images/*.png\"\n",
    "photos_list = glob.glob(photos_path)\n",
    "\n",
    "print_random_images(photos_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we need to convert our data to txt format. This is the format that Yolo expects. The txt file format should be like this : [class_id, x, y, width, height]. We also need to normalize the data between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the bounding box coordinates from the df DataFrame are converted to the format required for training a YOLO model. The converted coordinates are saved in separate text files for each image in the specified labels directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_pos = []\n",
    "y_pos = []\n",
    "frame_width = []\n",
    "frame_height = []\n",
    "\n",
    "labels_path = Path(\"./data/images/labels\")\n",
    "\n",
    "labels_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "save_type = 'w'\n",
    "\n",
    "for i, row in enumerate(df.iloc):\n",
    "    current_filename = str(row.file[:-4])\n",
    "    \n",
    "    width, height, xmin, ymin, xmax, ymax = list(df.iloc[i][-6:])\n",
    "    \n",
    "    x=(xmin+xmax)/2/width\n",
    "    y=(ymin+ymax)/2/height\n",
    "    width=(xmax-xmin)/width\n",
    "    height=(ymax-ymin)/height\n",
    "    \n",
    "    x_pos.append(x)\n",
    "    y_pos.append(y)\n",
    "    frame_width.append(width)\n",
    "    frame_height.append(height)\n",
    "    \n",
    "    txt = '0' + ' ' + str(x) + ' ' + str(y) + ' ' + str(width) + ' ' + str(height) + '\\n'\n",
    "    \n",
    "    if i > 0:\n",
    "        previous_filename = str(df.file[i-1][:-4])\n",
    "        save_type='a+' if current_filename == previous_filename else 'w'\n",
    "    \n",
    "    \n",
    "    with open(\"./data/images/labels/\" + str(row.file[:-4]) +'.txt', save_type) as f:\n",
    "        f.write(txt)\n",
    "        \n",
    "        \n",
    "df['x_pos']=x_pos\n",
    "df['y_pos']=y_pos\n",
    "df['frame_width']=frame_width\n",
    "df['frame_height']=frame_height\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the bounding box coordinates are converted to the YOLO format, where each line in the label file represents a single object detection and contains the class ID (assuming '0' for the 'license' class) and the normalized coordinates (x, y, width, height) of the bounding box. The converted coordinates are saved in text files with the same base name as the corresponding image file in the labels_path directory.\n",
    "\n",
    "Additionally, the code snippet updates the df DataFrame with the normalized coordinates x_pos, y_pos, frame_width, and frame_height for further analysis or training purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train test split\n",
    "now we need to split our data into training and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import splitfolders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the dataset is split into training and validation sets using the splitfolders library. The images from the input_folder are divided into two sets based on the specified ratio (80% for training and 20% for validation). The resulting sets are saved in the output_folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = Path(\"./data/images\")\n",
    "output_folder = Path(\"./data/images\")\n",
    "splitfolders.ratio(\n",
    "    input_folder,\n",
    "    output=output_folder,\n",
    "    seed=42,\n",
    "    ratio=(0.8, 0.2),\n",
    "    group_prefix=None\n",
    ")\n",
    "print(\"Moving files finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def walk_through_dir(dir_path: Path) -> None:\n",
    "    \"\"\"Prints dir_path content\"\"\"\n",
    "    for dirpath, dirnames, filenames in os.walk(dir_path):\n",
    "        print(f\"There are {len(dirnames)} directiories and {len(filenames)} files in '{dirpath}' folder \")\n",
    "\n",
    "    \n",
    "walk_through_dir(input_folder)\n",
    "print()\n",
    "walk_through_dir(output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "yaml_file = './data/images/plates.yaml'\n",
    "\n",
    "yaml_data = dict(\n",
    "    path = \"./data/images\",\n",
    "    train = \"train\",\n",
    "    val = \"val\",\n",
    "    nc = len(classes),\n",
    "    names = classes\n",
    ")\n",
    "\n",
    "with open(yaml_file, 'w') as f:\n",
    "    yaml.dump(yaml_data, f, explicit_start = True, default_flow_style = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After executing the code, the variable cuda_available will be True if CUDA is available, indicating that GPU acceleration is possible. If CUDA is not available, the variable will be False, indicating that only CPU computations will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "157 layers, 7012822 parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we train the model with the following parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd yolov5 && python train.py --workers 2 --img 320 --batch 32 --epochs 100 --data \"../data/images/plates.yaml\" --weights yolov5l.pt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualizing metrics\n",
    "more metrics can be found inside yolov5/runs/train/exp n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,15))\n",
    "plt.axis('off')\n",
    "plt.imshow(plt.imread(\"./yolov5/runs/train/exp39/results.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjust the file path in plt.imread() to the correct location of your YOLOv5 training results image. The figsize parameter sets the size of the figure to adjust the image display. The plt.axis('off') command turns off the axis labels and ticks to provide a cleaner display of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plt.axis('off')\n",
    "plt.imshow(plt.imread(\"./yolov5/runs/train/exp9/confusion_matrix.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference on video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "model = torch.hub.load('ultralytics/yolov5','custom',path=\"yolov5/runs/train/exp9/weights/last.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python detect.py --weights yolov5s.pt --source 'myVideoPath.mp4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
